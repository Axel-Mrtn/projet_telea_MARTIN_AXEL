{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c27f81",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-weight: bold; text-decoration: underline; text-decoration-color: red;\">\n",
    "    Projet SIGMA M2 : TELEA\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8956e28",
   "metadata": {},
   "source": [
    "**Auteur :** Martin Axel\n",
    "\n",
    "\n",
    "**Objectif :** Le but de ce projet est d’exploiter une série temporelle d’images Sentinel-2 pour analyser et caractériser les strates de végétation et les types de sols (notamment les landes) dans une zone d’étude.\n",
    " \n",
    "Cela implique d’implémenter une chaîne de traitement en Python comprenant l’analyse des échantillons obtenus par photo-interprétation, l’extraction d’indices spectraux pertinents, la réalisation de visualisations statistiques, ainsi que la production et l’évaluation d’une carte de strates à l’aide de méthodes de classification supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc2e14",
   "metadata": {},
   "source": [
    "### **Importation des bibliothèques nécessaire au projet :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Importation des bibliothèques\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Ajout du dossier de travail au PYTHONPATH\n",
    "sys.path.insert(0, \"/home/onyxia/work/\")\n",
    "\n",
    "# Fonctions personnelles\n",
    "import my_function as my\n",
    "\n",
    "# Fonctions libsigma\n",
    "from libsigma import read_and_write as rw\n",
    "from libsigma import classification as cla\n",
    "from libsigma import plots \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26d5b4",
   "metadata": {},
   "source": [
    "## **4.2 Analyse des échantillons** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2fe4bd",
   "metadata": {},
   "source": [
    "#### **4.2.1 Nombre d’échantillons** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef3cd1",
   "metadata": {},
   "source": [
    "##### **Nombre de polygones par classe :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins d’entrée / sortie\n",
    "ts_path = \"/home/onyxia/work/data/projet_eval\"\n",
    "in_vector = os.path.join(ts_path, \"PI_strates_pyrenees_32630.shp\")\n",
    "ref_image = os.path.join(ts_path, \"pyrenees_23-24_B02.tif\")\n",
    "samples_raster = \"/home/onyxia/work/results/samples_raster.tif\"\n",
    "\n",
    "# Dossier pour enregistrer les figures\n",
    "dir_fig = \"/home/onyxia/work/results/figure\"\n",
    "os.makedirs(dir_fig, exist_ok=True)\n",
    "\n",
    "# Lecture du shapefile d’échantillons\n",
    "sample_data = gpd.read_file(in_vector)\n",
    "\n",
    "# Groupement par strate et comptage du nombre de polygones par classe\n",
    "counts_label = sample_data.groupby(\"strate\").size()\n",
    "\n",
    "# Styles d’affichage\n",
    "colors = [\"tan\", \"yellowgreen\", \"peru\", \"forestgreen\"]\n",
    "names = {1: \"Sol Nu\", 2: \"Herbe\", 3: \"Landes\", 4: \"Arbre\"}\n",
    "\n",
    "# Création du graphique : nb de polygones par classe \n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "bars = ax.bar(counts_label.index.astype(int), counts_label.values, color=colors, zorder=3)\n",
    "\n",
    "# Paramétrage des axes et de l’affichage du graphique\n",
    "ax.set_xticks(counts_label.index.astype(int))\n",
    "ax.set_xticklabels([names.get(i, str(i)) for i in counts_label.index.astype(int)])\n",
    "ax.set_title(\"Nombre de polygones par classe\")\n",
    "ax.set_xlabel(\"Strate\")\n",
    "ax.set_ylabel(\"Nombre de polygones\")\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.7, zorder=0)\n",
    "\n",
    "# Ajout des valeurs numériques au-dessus de chaque barre du diagramme\n",
    "for bar in bars:\n",
    "    ax.annotate(f\"{int(bar.get_height())}\",\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords=\"offset points\",\n",
    "                ha=\"center\", va=\"bottom\", zorder=4)\n",
    "\n",
    "plt.tight_layout() # Ajuste automatiquement la disposition pour éviter les chevauchements\n",
    "plt.show() # Affiche le graphique à l'écran\n",
    "\n",
    "# Export de la figure en PNG (300 DPI) avec ajustement automatique des bordures\n",
    "fig.savefig(os.path.join(dir_fig, \"diag_baton_nb_poly_by_class.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print(  f\"Diagramme généré avec succès : \" f\"{os.path.join(dir_fig, 'diag_baton_nb_poly_by_class.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058bd47",
   "metadata": {},
   "source": [
    "### Répartition des polygones d’apprentissage par strate\n",
    "\n",
    "Ce graphique montre la distribution des polygones utilisés pour l’apprentissage, regroupés par classe de strate.\n",
    "\n",
    "* **Lecture du résultat :** Les classes *Herbe* et *Landes* sont les plus représentées en nombre de polygones, tandis que *Sol nu* et *Arbre* disposent de moins d’échantillons.\n",
    "* **Interprétation :** La base d’apprentissage présente donc un léger déséquilibre entre classes, ce qui peut influencer l’entraînement du modèle (classes majoritaires mieux apprises que les classes minoritaires).\n",
    "\n",
    "**Diagramme de flux :**\n",
    "![Flux de traitement pour générer l'histogramme de répartition des polygones par classe](/home/onyxia/work/projet_telea_MARTIN_AXEL/img/Diagramme_nb_polygone_classe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ce653",
   "metadata": {},
   "source": [
    "##### **Nombre de pixel par classe :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterisation du shapefile (champ \"strate\") sur la grille de ref_image via la fonction rasterisation\n",
    "my.rasterisation(in_vector, ref_image, samples_raster, \"strate\", dtype=\"Int32\")\n",
    "\n",
    "# Chargement des pixels de samples_raster en tableau NumPy\n",
    "arr3d = rw.load_img_as_array(samples_raster, verbose=False)\n",
    "arr = arr3d[:, :, 0]\n",
    "\n",
    "# Comptage des pixels par classe \n",
    "vals = arr[arr != 0]\n",
    "values, counts = np.unique(vals, return_counts=True)\n",
    "\n",
    "# Création du graphique : nb de pixels par classe \n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "bars = ax.bar(values.astype(int), counts, color=colors[:len(values)], zorder=3)\n",
    "\n",
    "ax.set_xticks(values.astype(int))\n",
    "ax.set_xticklabels([names.get(v, str(v)) for v in values.astype(int)])\n",
    "ax.set_title(\"Nombre de pixels par classe\")\n",
    "ax.set_xlabel(\"Strate\")\n",
    "ax.set_ylabel(\"Nombre de pixels\")\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.7, zorder=0)\n",
    "\n",
    "for bar in bars:\n",
    "    ax.annotate(f\"{int(bar.get_height())}\",\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, max(counts) * 0.01), textcoords=\"offset points\",\n",
    "                ha=\"center\", va=\"bottom\", zorder=4)\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show() \n",
    "\n",
    "fig.savefig(os.path.join(dir_fig, \"diag_baton_nb_pix_by_class.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "print( f\"Diagramme généré avec succès : \" f\"{os.path.join(dir_fig, 'diag_baton_nb_pix_by_class.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c7d0d",
   "metadata": {},
   "source": [
    "### Répartition des pixels après rasterisation\n",
    "\n",
    "Ce graphique présente la distribution des pixels issus de la rasterisation des polygones.\n",
    "\n",
    "* **Principe :** Le comptage est réalisé à partir du raster de strates obtenu après rasterisation.\n",
    "* **Paramètre clé :** Le paramètre `all_touched=True` est utilisée lors de la rasterisation. Tous les pixels touchant un polygone, y compris ceux situés en bordure, sont affectés à la classe correspondante. Ce choix permet de mieux représenter l’emprise réelle des polygones, mais augmente le nombre de pixels comptabilisés.\n",
    "* **Lecture du résultat :** La classe *Landes* domine en nombre de pixels, suivie par *Herbe*. Les classes *Sol nu* et *Arbre* sont moins représentées.\n",
    "* **Interprétation :** La répartition en pixels ne reflète pas strictement celle des polygones, en raison des différences de surface entre les objets et de l’utilisation de `all_touched=True`, qui accentue l’influence des contours.\n",
    "\n",
    "**Diagramme de flux :**\n",
    "![Flux de traitement pour générer l'histogramme de répartition des pixels par classe](/home/onyxia/work/projet_telea_MARTIN_AXEL/img/Diagramme_nb_pixel_classe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b84fd7",
   "metadata": {},
   "source": [
    "#### **4.2.2 Phénologie des strates, mise en évidence des landes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c06f6",
   "metadata": {},
   "source": [
    "#### **Création du raster d'ARI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2bb13",
   "metadata": {},
   "source": [
    "### Calcul de l’indice ARI (Anthocyanin Reflectance Index)\n",
    "\n",
    "Les landes que l’on cherche à caractériser appartiennent majoritairement à la famille des Éricacées. Ces formations végétales se distinguent notamment par une forte présence d’anthocyanes, des pigments végétaux jouant un rôle comparable à celui de la chlorophylle. La concentration en anthocyanes est particulièrement marquée en période automnale, ce qui confère aux landes une signature spectrale spécifique.\n",
    "\n",
    "Afin de caractériser cette signature, le **Normalized Anthocyanin Reflectance Index (ARI)** est calculé à partir des bandes spectrales correspondantes. Cet indice permet de mettre en évidence la présence relative d’anthocyanes dans la végétation et constitue un indicateur pertinent pour l’étude des strates végétales riches en ces pigments.\n",
    "\n",
    "La formule de l’indice ARI est définie comme suit :\n",
    "\n",
    "$$\n",
    "ARI = \\dfrac{\\dfrac{1}{B_{03}} - \\dfrac{1}{B_{05}}}{\\dfrac{1}{B_{03}} + \\dfrac{1}{B_{05}}}\n",
    "$$\n",
    "\n",
    "\n",
    "où :\n",
    "- \\(B03\\) correspond à la bande verte,\n",
    "- \\(B05\\) correspond à la bande du proche infrarouge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Calcul de l’indice ARI (série temporelle) à partir des bandes B03 et B05\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Correspondance entre types numpy et types GDAL\n",
    "data_type_match = {\n",
    "    'uint8': gdal.GDT_Byte,\n",
    "    'uint16': gdal.GDT_UInt16,\n",
    "    'uint32': gdal.GDT_UInt32,\n",
    "    'int16': gdal.GDT_Int16,\n",
    "    'int32': gdal.GDT_Int32,\n",
    "    'float32': gdal.GDT_Float32,\n",
    "    'float64': gdal.GDT_Float64\n",
    "}\n",
    "\n",
    "# Définition des chemins \n",
    "dirname = '/home/onyxia/work/data/projet_eval'\n",
    "out_dirname = '/home/onyxia/work/results'\n",
    "dir_B3 = os.path.join(dirname, 'pyrenees_23-24_B03.tif')\n",
    "dir_B5 = os.path.join(dirname, 'pyrenees_23-24_B05.tif')\n",
    "out_ari_filename = os.path.join(out_dirname, 'ARI_serie_temp.tif')\n",
    "\n",
    "# Ouverture du raster B03\n",
    "data_set_B3 = rw.open_image(dir_B3)\n",
    "# Chargement des pixels B03 en tableau NumPy\n",
    "img_B3 = rw.load_img_as_array(dir_B3)\n",
    "\n",
    "data_set_B5 = rw.open_image(dir_B5)\n",
    "img_B5 = rw.load_img_as_array(dir_B5)\n",
    "\n",
    "# Conversion en float pour le calcul des indices \n",
    "B3 = img_B3[:, :, :].astype('float32')\n",
    "B5 = img_B5[:, :, :].astype('float32')\n",
    "\n",
    "# Calcul de l’indice ARI via la fonction compute_ari_timeseries (série temporelle) \n",
    "ari = my.compute_ari_timeseries(B3, B5)\n",
    "\n",
    "# Écriture du raster ARI via la fonction write_image\n",
    "rw.write_image(\n",
    "    out_ari_filename,\n",
    "    ari,\n",
    "    data_set=data_set_B5,\n",
    "    gdal_dtype=data_type_match['float32'],\n",
    "    projection=None\n",
    ")\n",
    "\n",
    "# Définition de la valeur NoData \n",
    "ds = gdal.Open(out_ari_filename, gdal.GA_Update)\n",
    "band = ds.GetRasterBand(1)\n",
    "band.SetNoDataValue(-9999)\n",
    "band.FlushCache()\n",
    "ds = None\n",
    "\n",
    "print(f\"Raster ARI généré avec succès : {out_ari_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15104373",
   "metadata": {},
   "source": [
    "Dans cette étape, les rasters correspondant aux bandes spectrales B03 et B05 sont récupérés à partir des données d’entrée. Ces bandes sont ensuite chargées sous forme de tableaux NumPy afin de pouvoir être manipulées pour le calcul de l’indice.\n",
    "\n",
    "Les valeurs des bandes sont converties en type flottant (`float32`) afin d’assurer la stabilité numérique des calculs, notamment lors des opérations de division nécessaires au calcul de l’indice ARI. L’indice est alors calculé pixel par pixel pour l’ensemble de la série temporelle à partir des bandes B03 et B05, ce qui permet d’obtenir un raster multi-temporel représentant l’évolution spatiale et temporelle de l’ARI.\n",
    "\n",
    "Une fois le calcul effectué, le raster de l’indice ARI est exporté vers un fichier géoréférencé en conservant les informations spatiales du raster de référence. Enfin, une valeur NoData est définie afin d’identifier les pixels non valides et de garantir une utilisation correcte du raster lors des analyses ultérieures.\n",
    "\n",
    "\n",
    "**Diagramme de flux :**\n",
    "![Flux de traitement pour calculer le Normalized Anthocyanin Reflectance Index (NARI)](/home/onyxia/work/projet_telea_MARTIN_AXEL/img/DIagramme_raster_ARI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a06209",
   "metadata": {},
   "source": [
    "#### **Création du graphique de série temporelle moyenne d’ARI de chaque strate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Analyse des séries temporelles de l’indice ARI par strate\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Définition des dates d’acquisition \n",
    "dates = [\n",
    "    \"25/09/2023\", \"30/09/2023\", \"05/10/2023\", \"07/10/2023\", \"10/10/2023\",\n",
    "    \"12/10/2023\", \"19/11/2023\", \"16/12/2023\", \"25/01/2024\", \"13/03/2024\",\n",
    "    \"12/04/2024\", \"09/05/2024\", \"13/06/2024\", \"23/07/2024\", \"22/08/2024\"\n",
    "]\n",
    "\n",
    "# Extraction des pixels ARI par strate via la fonction get_samples_from_roi\n",
    "dict_X, dict_Y, dict_t = cla.get_samples_from_roi(\n",
    "    out_ari_filename,\n",
    "    samples_raster,\n",
    "    output_fmt=\"by_label\"\n",
    ")\n",
    "\n",
    "# Dictionnaire de correspondance entre codes et noms des strates\n",
    "names = {1: \"Sol nu\", 2: \"Herbe\", 3: \"Landes\", 4: \"Arbre\"}\n",
    "\n",
    "# Initialisation de la figure \n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Nombre de dates (bandes temporelles)\n",
    "n_dates = dict_X[list(dict_X.keys())[0]].shape[1]\n",
    "x = np.arange(n_dates)\n",
    "\n",
    "# Calcul et tracé des statistiques par strate \n",
    "# Pour chaque strate, la moyenne et l’écart-type de l’ARI sont calculés à chaque date afin de représenter la dynamique temporelle.\n",
    "for lab in sorted(dict_X.keys()):\n",
    "    X = dict_X[lab]\n",
    "\n",
    "    # Remplacement des valeurs NoData par NaN pour éviter leur prise en compte\n",
    "    X = np.where(X == -9999, np.nan, X)\n",
    "\n",
    "    mean = np.nanmean(X, axis=0)\n",
    "    std  = np.nanstd(X, axis=0)\n",
    "\n",
    "    ax.plot(x, mean, label=names.get(lab, f\"Strate {lab}\"))\n",
    "    ax.fill_between(x, mean - std, mean + std, alpha=0.2)\n",
    "\n",
    "# Mise en forme du graphique \n",
    "ax.set_xlabel(\"Dates d'acquisition\")\n",
    "ax.set_ylabel(\"ARI\")\n",
    "ax.set_title(\"Série temporelle ARI : moyenne ± écart-type par strate\")\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "ax.legend()\n",
    "\n",
    "# Remplacement des indices temporels par les dates réelles\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(dates, rotation=45, ha='right')\n",
    "\n",
    "# Affichage et sauvegarde de la figure\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(dir_fig, \"ARI_series.png\"), dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f\"Diagramme de la série temporelle ARI généré avec succès : {os.path.join(dir_fig, 'ARI_series.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565adbd",
   "metadata": {},
   "source": [
    "### Analyse de l’indice ARI par strate\n",
    "\n",
    "* **Évolution temporelle globale :**  \n",
    "  L’analyse de la série temporelle de l’ARI met en évidence une évolution cohérente de l’indice pour l’ensemble des strates étudiées. Toutes les classes présentent une chute marquée des valeurs d’ARI en décembre 2023, suivie d’une remontée progressive à partir du printemps 2024. Cette dynamique commune traduit la sensibilité de l’ARI aux conditions saisonnières et à l’activité végétative, ce qui est attendu pour un indice spectral lié à la végétation.\n",
    "\n",
    "* **Positionnement de la classe *Landes* :**  \n",
    "  La classe *Landes* se distingue globalement du *Sol nu* par des valeurs d’ARI plus élevées sur l’ensemble de la période étudiée. Elle présente également, selon les dates, des valeurs comparables ou légèrement supérieures à celles de la classe *Arbre*, notamment au printemps et en été 2024. Ces résultats suggèrent que l’ARI permet une discrimination partielle des landes par rapport à certaines strates.\n",
    "\n",
    "* **Similarité entre *Landes* et *Herbe* :**  \n",
    "  La distinction entre les classes *Landes* et *Herbe* apparaît plus délicate. Les valeurs moyennes d’ARI de ces deux strates sont très proches sur l’ensemble de la série temporelle, et leurs dynamiques temporelles sont similaires. Le fort chevauchement des intervalles moyenne ± écart-type indique une variabilité intra-classe comparable et des distributions d’ARI largement recouvrantes, rendant la discrimination entre ces deux strates difficile à partir de la moyenne de l’ARI seule.\n",
    "\n",
    "* **Apport et limites de la moyenne et de l’écart-type :**  \n",
    "  La moyenne et l’écart-type permettent de résumer le niveau moyen de l’ARI et sa dispersion autour de cette moyenne. Cependant, ces deux indicateurs restent insuffisants pour décrire la forme complète des distributions : ils ne renseignent pas sur l’asymétrie, la présence de valeurs extrêmes, ni sur la position de la médiane. Ainsi, deux strates peuvent présenter des moyennes et des écarts-types proches tout en ayant des distributions différentes. Il apparaît donc pertinent de compléter cette analyse par d’autres statistiques descriptives (médiane, quantiles, écart interquartile), ainsi que par des analyses de distribution ou des tests statistiques comparatifs afin de mieux comparer les strates.\n",
    "\n",
    "\n",
    "\n",
    "**Diagramme de flux :**\n",
    "![Flux de traitement pour générer le graphique de série temporelle d'ARI](/home/onyxia/work/projet_telea_MARTIN_AXEL/img/Diagramme_Graphique_Serie_Temp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d693ee",
   "metadata": {},
   "source": [
    "## **4.3 Production d’une carte de strates à l’échelle du pixel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7d631",
   "metadata": {},
   "source": [
    "### Classification supervisée des strates\n",
    "\n",
    "Dans cette partie, une approche de classification supervisée est mise en œuvre afin de discriminer les différentes strates à partir des données satellitaires Sentinel-2. Afin de maximiser l’information spectrale disponible pour l’apprentissage du modèle, il a été choisi de fusionner l’ensemble des bandes Sentinel-2 mises à disposition avec l’indice ARI préalablement calculé.\n",
    "\n",
    "Le choix de cette fusion repose sur un double objectif. D’une part, les bandes spectrales Sentinel-2 permettent de caractériser finement les propriétés radiométriques et structurelles de la surface (visible, proche infrarouge, red-edge et infrarouge à ondes courtes). D’autre part, l’indice ARI apporte une information complémentaire ciblée sur la présence d’anthocyanes, particulièrement pertinente pour la caractérisation des landes, souvent composées d’Éricacées. La combinaison de ces variables permet ainsi de constituer un jeu de variables explicatives riche et complémentaire, susceptible d’améliorer les performances de classification.\n",
    "\n",
    "Le modèle utilisé pour la classification est un **Random Forest**. Il s’agit d’un algorithme couramment mobilisé en télédétection pour la classification supervisée, notamment car il est robuste face au bruit, capable de gérer un grand nombre de variables explicatives et généralement performant dans des contextes multi-classes. Afin d’optimiser ses hyperparamètres et de limiter les risques de sur-apprentissage, une **recherche par grille (GridSearchCV)** est mise en œuvre, couplée à une validation croisée.\n",
    "\n",
    "\n",
    "L’évaluation du modèle repose sur une **validation croisée stratifiée avec contrainte de groupes** (`StratifiedGroupKFold`). Cette stratégie permet à la fois de conserver une répartition équilibrée des classes dans les plis et d’éviter toute fuite d’information entre les ensembles d’apprentissage et de test, en imposant qu’un même groupe spatial ne soit jamais présent simultanément dans les deux ensembles. Les performances sont ensuite analysées à l’aide de métriques globales (accuracy) et de métriques par classe (précision, rappel et F1-score), agrégées sur l’ensemble des plis de la validation croisée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45f72a",
   "metadata": {},
   "source": [
    "#### **4.3.2 Stratégie de validation (GridSearchCV)** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fd5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Construction du stack multi-bandes fusionné (Sentinel-2 + ARI)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Liste des bandes spectrales Sentinel-2 utilisées\n",
    "bands = [\n",
    "    \"B02\",\n",
    "    \"B03\",\n",
    "    \"B04\",\n",
    "    \"B05\",\n",
    "    \"B06\",\n",
    "    \"B07\",\n",
    "    \"B08\",\n",
    "    \"B8A\",\n",
    "    \"B11\",\n",
    "    \"B12\"\n",
    "]\n",
    "\n",
    "# Construction du stack fusionné via la fonction create_feature_stack \n",
    "stack_fused, ds_ref = my.create_feature_stack(\n",
    "    folder=ts_path,\n",
    "    prefix=\"pyrenees_23-24\",\n",
    "    bands=bands,\n",
    "    ari_path=out_ari_filename\n",
    ")\n",
    "\n",
    "# Écriture du raster fusionné \n",
    "out_fused = \"/home/onyxia/work/results/py_ari_stack.tif\"\n",
    "rw.write_image(\n",
    "    out_fused,\n",
    "    stack_fused,\n",
    "    data_set=ds_ref,\n",
    "    nb_band=stack_fused.shape[2]\n",
    ")\n",
    "\n",
    "print(f\"Stack fusionné généré avec {stack_fused.shape[2]} bandes : {out_fused}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46504b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Extraction des échantillons pour l’apprentissage supervisé\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Rasterisation du shapefile (champ \"id\")\n",
    "samples_raster_id = '/home/onyxia/work/results/samples_raster_id.tif'\n",
    "my.rasterisation(in_vector, ref_image, samples_raster_id, \"id\", dtype=\"Int32\")\n",
    "\n",
    "# Extraction des variables explicatives (X), des classes (Y) et des positions des pixels à partir du stack fusionné\n",
    "X, Y, t = cla.get_samples_from_roi(out_fused, samples_raster)\n",
    "\n",
    "# Extraction des identifiants de groupes \n",
    "_, groups, _ = cla.get_samples_from_roi(out_fused, samples_raster_id)\n",
    "\n",
    "# Mise en forme des vecteurs cibles et des groupes\n",
    "Y = np.asarray(Y).reshape(-1)\n",
    "groups = np.asarray(groups).reshape(-1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Définition du modèle et de la grille d’hyperparamètres\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Initialisation du classifieur Random Forest\n",
    "rf = RF(random_state=0, n_jobs=-1)\n",
    "\n",
    "# Grille d’hyperparamètres\n",
    "param_grid = {\n",
    "    \"n_estimators\": [150, 300],\n",
    "    \"max_depth\": [None, 20],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"min_samples_leaf\": [1, 5],\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Validation croisée stratifiée avec contrainte de groupes\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Définition d’une validation croisée stratifiée en 5 plis, avec mélange des données et graine aléatoire fixée pour garantir la reproductibilité des résultats\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Recherche des meilleurs hyperparamètres par GridSearch\n",
    "grid = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entraînement du modèle avec prise en compte des groupes\n",
    "grid.fit(X, Y, groups=groups)\n",
    "\n",
    "# Affichage des meilleurs paramètres et de la performance associée\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Récupération du meilleur modèle entraîné\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Évaluation du modèle par validation croisée groupée\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "list_cm = []          # matrices de confusion\n",
    "list_accuracy = []    # accuracies globales\n",
    "list_report = []      # rapports de classification par classe\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Boucle sur les folds de la validation croisée\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "for train_idx, test_idx in cv.split(X, Y, groups=groups):\n",
    "\n",
    "    # Séparation apprentissage / test\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "\n",
    "    # Clonage du meilleur modèle trouvé par GridSearch\n",
    "    clf = clone(best_model)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    # Prédiction sur le jeu de test\n",
    "    Y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcul et stockage de la matrice de confusion\n",
    "    list_cm.append(\n",
    "        confusion_matrix(Y_test, Y_pred, labels=np.unique(Y))\n",
    "    )\n",
    "\n",
    "    # Calcul et stockage de l’accuracy globale\n",
    "    list_accuracy.append(\n",
    "        accuracy_score(Y_test, Y_pred)\n",
    "    )\n",
    "\n",
    "    # Calcul et stockage des métriques par classe\n",
    "    rep = classification_report(\n",
    "        Y_test,\n",
    "        Y_pred,\n",
    "        labels=np.unique(Y),\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    list_report.append(pd.DataFrame(rep).T)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Agrégation des résultats sur l’ensemble des folds\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Moyenne de la matrice de confusion\n",
    "array_cm = np.array(list_cm)\n",
    "mean_cm = array_cm.mean(axis=0)\n",
    "\n",
    "# Moyenne et écart-type de l’accuracy globale\n",
    "array_accuracy = np.array(list_accuracy)\n",
    "mean_accuracy = array_accuracy.mean()\n",
    "std_accuracy = array_accuracy.std()\n",
    "\n",
    "# Moyenne et écart-type des métriques par classe\n",
    "all_reports = pd.concat(list_report, keys=range(len(list_report)))\n",
    "mean_df_report = all_reports.groupby(level=1).mean()\n",
    "std_df_report  = all_reports.groupby(level=1).std()\n",
    "\n",
    "print(f\"OA = {mean_accuracy:.3f} ± {std_accuracy:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Visualisation des performances\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Affichage de la matrice de confusion moyenne\n",
    "plots.plot_cm(mean_cm, labels=list(np.unique(Y)))\n",
    "plt.show()\n",
    "\n",
    "# Barplot des métriques par classe (precision / recall / f1-score)\n",
    "class_labels = [str(l) for l in np.unique(Y)]\n",
    "mean_cls = mean_df_report.loc[class_labels, [\"precision\", \"recall\", \"f1-score\"]]\n",
    "std_cls  = std_df_report.loc[class_labels,  [\"precision\", \"recall\", \"f1-score\"]]\n",
    "\n",
    "ax = mean_cls.plot.bar(yerr=std_cls, figsize=(10, 7), zorder=2)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Qualité de classification par classe\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab269dcc",
   "metadata": {},
   "source": [
    "**Diagramme de flux :**\n",
    "![Flux de traitement pour générer le graphique de série temporelle d'ARI](/home/onyxia/work/projet_telea_MARTIN_AXEL/img/Diagramme_Pipeline_Classification_Supervisée.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615e0c7",
   "metadata": {},
   "source": [
    "#### **4.3.3 Contribution des variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13828d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Analyse de l’importance des variables du modèle Random Forest\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Récupération des importances calculées par le Random Forest\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Nombre total de variables utilisées par le modèle\n",
    "n_features = importances.shape[0]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Définition des dates de la série temporelle\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Dates d’acquisition des images Sentinel-2 (ordre chronologique)\n",
    "n_dates = len(dates)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Reconstruction du nom des variables (bandes × dates)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Vérification que le nombre total de variables est cohérent avec une structure multi-temporelle\n",
    "if n_features % n_dates == 0:\n",
    "    n_series = n_features // n_dates\n",
    "    print(\"n_series temporelles =\", n_series)\n",
    "\n",
    "    if n_series == len(bands) + 1:\n",
    "        series_names = bands + [\"ARI\"]\n",
    "    else:\n",
    "        series_names = [f\"S{i+1}\" for i in range(n_series)]\n",
    "\n",
    "    # Création des noms des variables sous la forme :\n",
    "    feature_names = []\n",
    "    for s in series_names:\n",
    "        for d in dates:\n",
    "            feature_names.append(f\"{s}_{d}\")\n",
    "\n",
    "\n",
    "# Sécurité : vérification de la cohérence\n",
    "assert len(feature_names) == n_features\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Création du tableau des contributions des variables\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Association du nom des variables et de leur importance\n",
    "df_imp = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "})\n",
    "\n",
    "# Tri décroissant selon l’importance\n",
    "df_imp = df_imp.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Affichage des variables les plus contributives\n",
    "display(df_imp.head(10))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Visualisation des variables les plus importantes\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Sélection des 20 variables les plus discriminantes\n",
    "top_n = 20\n",
    "df_top = df_imp.head(top_n)\n",
    "\n",
    "# Barplot horizontal \n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.barh(df_top[\"feature\"][::-1], df_top[\"importance\"][::-1], color=plt.cm.Blues((df_top[\"importance\"][::-1] / df_top[\"importance\"].max())))\n",
    "plt.xlabel(\"Degrés de contribution\")\n",
    "plt.xlabel(\"Degrés de contribution\")\n",
    "plt.title(f\"{top_n} variables les plus importantes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1fdb0",
   "metadata": {},
   "source": [
    "#### **4.3.4 Production de la carte finale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6909d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Application du modèle sur l’image complète et génération de la carte de strates\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "out_classif = \"/home/onyxia/work/results/carte_strates.tif\"\n",
    "\n",
    "# Extraction des pixels + prédiction\n",
    "X_img, _, t_img = cla.get_samples_from_roi(out_fused, out_fused)\n",
    "Y_pred = best_model.predict(X_img)\n",
    "\n",
    "# Reconstruction de la carte\n",
    "ds = rw.open_image(ref_image)\n",
    "nb_row, nb_col, _ = rw.get_image_dimension(ds)\n",
    "\n",
    "ref_data = ds.GetRasterBand(1).ReadAsArray()  # pour le masque NoData/NaN\n",
    "\n",
    "img = np.zeros((nb_row, nb_col, 1), dtype=\"uint8\")\n",
    "img[t_img[0], t_img[1], 0] = Y_pred\n",
    "\n",
    "# Masque : zones sans donnée dans l’image de référence\n",
    "img[np.isnan(ref_data), 0] = 0\n",
    "\n",
    "# Écriture\n",
    "rw.write_image(out_classif, img, data_set=ds, gdal_dtype=data_type_match[\"uint8\"], nb_band=1)\n",
    "\n",
    "# Fix NoData à 0\n",
    "ds_out = gdal.Open(out_classif, gdal.GA_Update)\n",
    "ds_out.GetRasterBand(1).SetNoDataValue(0)\n",
    "ds_out = None\n",
    "ds = None\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Affichage de la carte des strates dans le notebook\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Lecture du raster classifié \n",
    "arr3d = rw.load_img_as_array(out_classif, verbose=False)\n",
    "carte = arr3d[:, :, 0].astype(np.uint8)\n",
    "\n",
    "# Liste de 5 couleurs (le premier 'white' pour la valeur 0)\n",
    "colors_map = ['white',\"tan\", \"yellowgreen\", \"peru\", \"forestgreen\"]\n",
    "\n",
    "# Création d’une palette de couleurs discrètes pour les classes de strates\n",
    "my_cmap = ListedColormap(colors_map)\n",
    "\n",
    "# Définition des bornes associées aux valeurs de classes (permet d’assurer une correspondance exacte entre valeurs et couleurs)\n",
    "bounds = [-0.5, 0.5, 1.5, 2.5, 3.5, 4.5]\n",
    "\n",
    "# Normalisation discrète des valeurs de classes à partir des bornes définies\n",
    "norm = BoundaryNorm(bounds, my_cmap.N)\n",
    "\n",
    "# Création de la figure pour l’affichage de la carte classifiée\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Affichage de la carte des strates avec la colormap et la normalisation discrète\n",
    "plt.imshow(img[:, :, 0], cmap=my_cmap, norm=norm)\n",
    "\n",
    "# Construction manuelle de la légende à partir des couleurs et des noms des strates\n",
    "for i, val in enumerate([1, 2, 3, 4], start=1):\n",
    "    plt.plot([], [], color=colors_map[i], label=names[val], linewidth=10)\n",
    "\n",
    "# Ajout de la légende, suppression des axes et affichage de la figure\n",
    "plt.legend(title=\"Strates\", loc=\"lower left\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Vérification de la création du raster de classification et affichage d’un message de confirmation\n",
    "if os.path.exists(out_classif):\n",
    "    print(f\"Carte des strates générée avec succès : {out_classif}\")\n",
    "else:\n",
    "    print(\"Erreur : la carte des strates n’a pas été générée.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b008b0",
   "metadata": {},
   "source": [
    "#### **4.3.5 Analyse des résultats**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
